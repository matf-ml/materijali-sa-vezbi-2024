{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikacija teksta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osim u obradi slika, konvolutivne neuronske mreže mogu se koristiti i u obradi teksta. Sledeći primer se odnosi na jednu takvu primenu u kojoj se 1D konvolutivne mreže koriste za klasifikaciju filmskih pregleda na pozitivne i negativne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src='assets/1CovNets_for_NLP.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U osnovi ovog pristupa je sledeća ideja. Pojedinačne reči teksta je potrebno prikazati kao vektore, a zatim konvolucijskim prozorima posmatrati njihove okoline. Na taj način može da se nauči o kontekstu pojave reči i njenoj semantici. Mi smo do sada videli već neke načine za predstavljanje reči, na primer, koristili smo Tf-Idf reprezentacije. U ovom primeru ćemo pustiti da sama mapira reči u vektore odgovarajućih dužina. Ta pojava se zove ugnježdavanje (engl. embedding).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvo ćemo učitati sve neophodne biblioteke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matftorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korak 1: Učitavanje skupa podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za učitavanje podataka iskoristićemo podršku Keras biblioteke. Skup podataka sa kojim radimo se zove `imdb` i, kao što smo najavili, sadrži kolekciju filmskih pregleda. Prilikom učitavanja ovog skupa potrebno je da parametrom `max_features` navedemo koliko će najfrekventnijih reči vokabulara biti uzeto u obzir. Na nivou pojedinačnih pregleda će biti zadržane reči koje pripadaju ovom skupu, dok će preostale reči biti obrisane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi ćemo se opredeliti za praćenje 2000 najfrekventnijih reči."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = IMDB(root='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n"
     ]
    }
   ],
   "source": [
    "for label, line in train_iter:\n",
    "    print(label, line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svaku rečenicu iz skupa podataka ćemo predstaviti kao niz brojeva. Kako bi ovo uradili prvo je potrebno da pronađemo sve reči koje postoje u tekstu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for label, line in train_iter:\n",
    "    counter.update(tokenizer(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon pronalaska svih reči napravićemo njihov rečnik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'the': 4\n",
      "Word corresponding to index 10: to\n"
     ]
    }
   ],
   "source": [
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True) # sortiramo tokene po frekvenciji\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "recnik = vocab(ordered_dict, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=400) # pravimo vocabular sa tokenima koji se pojavljuju barem 400 puta\n",
    "print(\"Index of 'the':\", recnik['the'])\n",
    "print(\"Word corresponding to index 10:\", recnik.get_itos()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(recnik, texts):\n",
    "    return [torch.tensor([recnik[token] if token in recnik else recnik['<unk>'] for token in tokenizer(text)]) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_texts = zip(*train_iter)\n",
    "test_labels, test_texts = zip(*test_iter)\n",
    "train_indices = text_to_indices(recnik, train_texts)\n",
    "test_indices = text_to_indices(recnik, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U skupu za treniranje, kao i u skupu za testiranje, imamo po 25000 pregleda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korak 2: Priprema podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da bismo sve preglede mogli da obrađujemo na isti način, moramo usaglasiti i njihove dužine. Mi ćemo se ograničiti na prvih 400 reči pregleda. Ukoliko je tekst duži od 400 reči, doći će do odsecanja sadržaja. Ukoliko je tekst kraći od 400 reči, dopunićemo ga nulama (podrazumevano se nule dodaju na početku sekvence). Funkcija koja ima ovo ponašanje i koju ćemo iskoristiti u radu je `pad_sequence` koja pripada skupu `keras.preprocessing`  funkcija za pripremu sekvencijalnih podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "train_indices_padded = pad_sequence(train_indices, batch_first=True)[:, :max_len]\n",
    "test_indices_padded = pad_sequence(test_indices, batch_first=True)[:, :max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 400])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U skupu ciljnih promenljivih imamo binarne vrednosti 0 i 1 koje redom predstavljuju negativne tj. pozitivno ocenjene preglede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broj pozitivnih i broj negativnih pregleda je jednak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 12500, 12500])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korak 3: Pravljenje modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na početku naše mreže naći će se `Embedding` sloj. Ovaj sloj svakoj reči treba da pridruži vektorsku reprezentaciju dužine 128. Prvi argument sloja predstavlja veličinu vokabulara, drugi željenu dužinu ugnježdenih reprezentacija i treći maksimalnu dužinu pojedinačnih sekvenci. <img src='assets/embeddings.png'>\n",
    "\n",
    "\n",
    "\n",
    "U ostatku mreže će se smenjivati 1D konvolutivni i 1D agregacioni slojevi uz izmenu da su korišćeni kerneli jednodimenzioni.  <img src='assets/1D_convolution_animated.gif'> \n",
    "\n",
    "Ako je veličina jednodimenzionog kernela $k$ to znači da će se posmatrati sekvence $k$ uzastopnih reči. Računica koja stoji iza ovakvog prolaza kernelom kroz ulazni tekst je prikazana na slici ispod. Ako se koristi $m$ filtera za uočenih $k$ uzastopnih reči kao izlaz možemo očekivati vektor dužine $m$.\n",
    "<img src='assets/1D_convolution_with_math.png'>\n",
    "\n",
    "Na slici ispod možemo videti i kako izgleda operacija agregacije za jednodimenzioni slučaj. \n",
    "<img src='assets/1D_pooling.png'>\n",
    "\n",
    "\n",
    "Na kraju mreže će se naći gusti sloj sa jednim neuronom i sigmoidnom aktivacijom koji će omogućiti binarni izlaz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(IMDbModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 32, kernel_size=7)\n",
    "        self.pool1 = nn.MaxPool1d(5)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=7)\n",
    "        self.pool2 = nn.MaxPool1d(5)\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)  # Conv1d expects input in the format (batch_size, embedding_dim, seq_len)\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "model = IMDbModel(len(recnik), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMDbModel(\n",
       "  (embedding): Embedding(1364, 128)\n",
       "  (conv1): Conv1d(128, 32, kernel_size=(7,), stride=(1,))\n",
       "  (pool1): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 32, kernel_size=(7,), stride=(1,))\n",
       "  (pool2): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (global_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao funkciju greške koristićemo binarnu unakrsnu entropiju, a kao optimizator Adam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mrežu ćemo trenirati u 10 epoha, koristeći paketiće veličine 128 instanci. Uspešnost treniranja pratićemo na validacionom skupu veličine 20% ukupnog skupa podataka. Treniranje će malo potrajati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_indices_padded, torch.tensor(train_labels), test_size=0.2, random_state=42, stratify=train_labels)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(list(zip(X_valid, y_valid)), batch_size=batch_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = matftorch.train_classification(model, criterion, optimizer, epochs, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sam tok treniranja mreže možemo ispratiti grafički."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[43mepochs\u001b[49m), train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, epochs), val_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss')\n",
    "plt.plot(np.arange(0, epochs), train_losses, label='train')\n",
    "plt.plot(np.arange(0, epochs), val_losses, label='val')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(np.arange(0, epochs), train_accuracies, label='train')\n",
    "plt.plot(np.arange(0, epochs), val_accuracies, label='val')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa ovih grafikona možemo primetiti da se posle četvrte epohe model preprilagođava podacima i da ima smisla dodati regularizaciju u vidu `dropout` sloja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korak 4: Evaluacija modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mrežu ćemo evaluirati na skupu za testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.358565092086792\n",
      "Test accuracy: 0.8410400152206421\n"
     ]
    }
   ],
   "source": [
    "X_test = test_indices_padded\n",
    "y_test = torch.tensor(test_labels)\n",
    "model.eval()\n",
    "test_loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=batch_size)\n",
    "\n",
    "score = matftorch.test_classification(model, criterion, test_loader)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S obzirom da smo u učenju koristili svega 2000 reči ima smisla probati kako se model ponaša ukoliko se radi sa većim vokabularom. Takođe, ima smisla probati i sa nešto drugačijim ugnježđenim reprezentacijama, na primer, nešto kraćim. Ove zadatke ostavljamo za vežbu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo još testirati kako se naš model ponaša za novi pregled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = \"this is super interesting and funny movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = recnik.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review_in_indexes = [word_index[word] for word in new_review.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 6, 1162, 218, 2, 160, 17]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_review_in_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_review_tensor = torch.tensor(new_review_in_indexes)\n",
    "padded_sequence = pad_sequence([new_review_tensor], batch_first=True, padding_value=0, total_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,   11,    6, 1162,\n",
       "         218,    2,  160,   17]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model(padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5218582], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class = int(score>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korak 5: Čuvanje modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Čuvanje Keras modela obuhvata čuvanje informacija o arhitekturi, parametrima, konfiguraciju treniranja i stanja optimizatora tako da se nesmetano može nastaviti sa radom nakon njegovog ponovnog učitavanja. Modeli se čuvaju u HDF5 formatu koji se koristi za čuvanje velikih količina numeričkih podataka. Za izdvajanje informacija iz ovakvih datoteka možemo koristiti funkcionalnosti biblioteke h5py. Nju možemo instalirati komandom `conda install -c anaconda h5py` u skladu sa [zvaničnim smernicama](https://anaconda.org/anaconda/h5py). Više o samoj biblioteci može se pronaći i na [zvaničnoj stranici](https://www.h5py.org/). \n",
    "\n",
    "Mi ćemo u radu koristiti Keras podršku dostupnu kroz `load_model` funkcionalnosti. Funkcijom `save` se čuva model, a funkcijom `load_model` učitava postojeći. \n",
    "\n",
    "Čuvanje modela može biti naročito važno ukoliko je za njegovo treniranje potrebno puno resursa i vremena. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model.pth')\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('models/model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "    Za dalje istraživanje: \n",
    "    <a href='https://lena-voita.github.io/nlp_course/models/convolutional.html'> Convolutional Neural Networks for Text </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
